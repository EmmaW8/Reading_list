# [ICLR 2020](https://openreview.net/group?id=ICLR.cc/2020/Conference) Interesting papers
>There is nerver nothing we can do.


## Generative Model

* [**promising results!**] [ U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation ](https://openreview.net/pdf?id=BJlZ5ySKPH) [[Tensorflow](https://github.com/taki0112/UGATIT)]: Style transfer

* [**Discriminator**] [Real or not  real, that is the question](https://openreview.net/pdf?id=B1lPaCNtPB) [[PyTorch](https://github.com/kam1107/RealnessGAN)]: Change the output of discriminator to a distribution with a vector size of 8 (followed by KL loss), which is similar to the extended soft label.

* [**Understanding generative model**] [Do deep generative models know what they don't know](https://openreview.net/forum?id=H1xwNhCcYm) 

* :star::star::star::star::star: [**Robust GAN**] [Optimal strategies against generative attacks](https://openreview.net/pdf?id=BkgzMCVtPB) [[PyTorch](https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks)]: GAN in the middle networks. Find the optimal solution to against attacks, with analysis of how to attack with leaked samples.

* [**Loss function**] [Improving Adversarial Robustness Requires Revisiting Misclassified Examples](https://openreview.net/pdf?id=rklOg6EFwS) :  [Mark](https://iclr.cc/virtual/poster_rklOg6EFwS.html)

* [**Comparison discriminator**] [Self-Adversarial Learning with Comparative Discrimination for Text Generation ](https://openreview.net/pdf?id=B1l8L6EtDS)

* [Controlling generative models with continuous factors of variations](https://openreview.net/pdf?id=H1laeJrKDB)

* [**Learning para as loss weight**] [You Only Train Once: Loss-Conditional Training of Deep Networks](https://openreview.net/pdf?id=HyxY6JHKwr)

* [**Augmentation**] [Adversarial AutoAugment](https://openreview.net/pdf?id=ByxdUySKvS) : RL

  



## Generalization

* [Identity Crisis: Memorization and Generalization Under Extreme Overparameterization](https://openreview.net/forum?id=B1l6y0VFPr): FC layers. Low level features show identity ability, while high-level features output constant information.



## Representation Learning
* [Target-Embedding Autoencoders for Supervised Representation Learning](https://openreview.net/pdf?id=BygXFkSYDH) : VAE usually reconstracts X, but in this paper, it reconstracts Y(Y is high-dimensional). Application:  multivariate sequence forecasting

* :star::star::star::star::star: [**Unsupervised clustering**] [Self-labelling via simultaneous clustering and representation learning ](https://openreview.net/pdf?id=Hyx-jyBFPr) [[PyTorch](https://github.com/yukimasano/self-label)]: random generated labels & optimization & update labels (representation learning) + linear program solving 

* [Interpretation] [Rotation-invariant clustering of neuronal responses in primary visual cortex ](https://openreview.net/pdf?id=rklr9kHFDB) 

* [Multi-view information] [Learning Robust Representations via Multi-View Information Bottleneck ](https://openreview.net/pdf?id=B1xwcyHFDr)

  

## Domain Adaptation

* [Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification](https://openreview.net/forum?id=rJlnOhVYPS) : re-identification, mean teacher, 4 models, triplet loss

* [Domain Adaptive Multibranch Networks](https://openreview.net/pdf?id=rJxycxHKDS)

   

  

## Multi-modal (image/text)

* [ Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings ](https://openreview.net/pdf?id=SJxE8erKDH) [[PyTorch](https://github.com/visinf/lnfmm)]: image caption
* [From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech ](https://openreview.net/pdf?id=H1guaREYPr): using voice to generate face, interesting.




## Graph Neural Network
* [Deep Graph Matching Consensus](https://openreview.net/pdf?id=HyeJf1HKvS) [[PyTorch](https://github.com/rusty1s/deep-graph-matching-consensus)]: Idea (neighboors should contain same information in two similar images) is good, which might be used in somewhere else.
* [DropEdge: Towards Deep Graph Convolutional Networks on Node Classification ](https://openreview.net/pdf?id=Hkx1qkrKPr) [[PyTorch](https://github.com/DropEdge/DropEdge)]



## Self-supervised Learning

* :star::star::star::star:  [ A crical analysis of self-supervision, or what we can learn from a single image](https://openreview.net/pdf?id=B1esx6EYvr) : Self supervision with one image could learn low-level features with high quality

  

## Semi-supervised Learning

* [**Application**] [Automatically Discovering and Learning New Visual Categories with Ranking Statistics](https://openreview.net/pdf?id=BJl2_nVFPB) [[PyTorch](http://www.robots.ox.ac.uk/~vgg/research/auto_novel)]: 应用流也能中ICLR了.. self-supervision + supervised-learning + pesudo label + incremental learning  

* [ Deep Semi-Supervised Anomaly Detection ](https://openreview.net/pdf?id=HkgH0TEYwH)

* [**Remove noise labelled data to semi-supervised learning**] [ SELF: Learning to Filter Noisy Labels with Self-Ensembling ](https://openreview.net/pdf?id=HkgsPhNYPS)

* [**Mixmatch upgrade**] [ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring](https://openreview.net/pdf?id=HklkeR4KPB)

* [**Semi-supervised**] [DivideMix: Learning with Noisy Labels as Semi-supervised Learning](https://openreview.net/pdf?id=HJgExaVtwr): filter noise label, then trest them as unlabelled data, apply pseudo label for mixmatch.

  

## Weakly-supervised Learning

* [Weakly Supervised Clustering by Exploiting Unique Class Count](https://openreview.net/pdf?id=B1xIj3VYvr): predict the class No. within one images. 

  

## Active Learning

* [certainty and diversity] [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds](https://openreview.net/pdf?id=ryghZJBKPS) [Oral]



## Disentangle

* [Weakly Supervised Disentanglement with Guarantees](https://openreview.net/pdf?id=HJgSwyBKvr)

  

## Noise Lable

* [**Remove noise labelled data to semi-supervised learning**] [ SELF: Learning to Filter Noisy Labels with Self-Ensembling ](https://openreview.net/pdf?id=HkgsPhNYPS)

* [**Regularization**] [Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee](https://openreview.net/pdf?id=Hke3gyHYwH) [[Code](https://drive.google.com/drive/folders/1TDlUuL0I-EzIybjz2pMAgyaYP5F6dq6o)]

* [**Semi-supervised**] [DivideMix: Learning with Noisy Labels as Semi-supervised Learning](https://openreview.net/pdf?id=HJgExaVtwr): filter noise label, then trest them as unlabelled data, apply pseudo label for mixmatch.

  

## Network Architecture
* [**Semantic Segmentation**] [FasterSeg:Searching for Faster Real-time Semantic Segmentation](https://openreview.net/pdf?id=BJgqQ6NYvB) [[PyTorch](https://github.com/TAMU-VITA/FasterSeg)]: network search + teacher/student knowledge distilation

  


## Network Component Upgrade
* [**Activation**] [Enhancing adversarial defence by k-winners-take-all](https://openreview.net/pdf?id=Skgvy64tvr) [[PyTorch](https://github.com/a554b554/kWTA-Activation)]: For improving the robustness, similar to ReLU but with a ratio to keep the values instead of using threshold 0.

* [**Curriculum Loss**] [ Curriculum Loss: Robust Learning and Generalization against Label Corruption ](https://openreview.net/pdf?id=rkgt0REKwS)

* [**Normalization**] [Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks](https://openreview.net/pdf?id=ByxtC2VtPB) [[PyTorch](https://github.com/P2333/Mixup-Inference)]: Adding permutations to the samples to improve the robustness.

* [**Optimization**] [Don't Use Large Mini-batches, Use Local SGD](https://openreview.net/pdf?id=B1eyO1BFPr) multi-GPU, before communication, more inference...

* [**Optimization**] [Large Batch Optimization for Deep Learning: Training BERT in 76 minutes ](https://openreview.net/pdf?id=Syx4wnEtvH) [[TensorFlow](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py)]

  

## Meta-Learning
* [Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks](https://openreview.net/pdf?id=rkeZIJBYvr) [[Code](https://github.com/haebeom-lee/l2b)][Oral]

* [ A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms ](https://openreview.net/pdf?id=ryxWIgBFPS)

  


## Point Cloud
* [Unpaired Point Cloud Completion on Real Scans using Adversarial Training](https://openreview.net/pdf?id=HkgrZ0EYwB) [[TensorFlow](https://github.com/xuelin-chen/pcl2pcl-gan-pub)]: GAN + super-resolution



## Mobile Network

* [**Model Compression**] [Once for All: Train One Network and Specialize it for Efficient Deployment](https://openreview.net/pdf?id=HylxE1HKwS) [[PyTorch](https://github.com/mit-han-lab/once-for-all)]

* 